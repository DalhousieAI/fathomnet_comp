{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move taxon annotations over to main file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(\"data/train/annotations.csv\")\n",
    "hierarchy_annotations = pd.read_csv(\"data/train/hierarchy_labels_train.csv\")\n",
    "\n",
    "train_df[\"id\"] = train_df[\"path\"].apply(lambda x: x.split(\"/\")[-1].split(\".\")[0])\n",
    "hierarchy_annotations[\"id\"] = hierarchy_annotations[\"annotation_id\"].apply(lambda x: x.split(\".\")[0])\n",
    "\n",
    "# Enable this line if hierarchical ids are in the format \"roi_image\"\n",
    "# hierarchy_annotations[\"id\"] = hierarchy_annotations[\"id\"].apply(lambda x: x.split(\"_\")[-1] + \"_\" + x.split(\"_\")[0])\n",
    "\n",
    "# Make hierarchy_annotations headers lowercase\n",
    "hierarchy_annotations.columns = hierarchy_annotations.columns.str.lower()\n",
    "# Move domain,kingdom,phylum,class,order,family,genus,species from hierarchy_annotations to train_df based on id\n",
    "# Create dictionary to map id to hierarchy annotations\n",
    "hierarchy_annotations = hierarchy_annotations[[\"id\", \"domain\", \"kingdom\", \"phylum\", \"class\", \"order\", \"family\", \"genus\", \"species\"]]\n",
    "hierarchy_dict = hierarchy_annotations.set_index(\"id\").T.to_dict(\"list\")\n",
    "\n",
    "train_df[\"domain\"] = train_df[\"id\"].map(lambda x: hierarchy_dict[x][0] if x in hierarchy_dict else None)\n",
    "train_df[\"kingdom\"] = train_df[\"id\"].map(lambda x: hierarchy_dict[x][1] if x in hierarchy_dict else None)   \n",
    "train_df[\"phylum\"] = train_df[\"id\"].map(lambda x: hierarchy_dict[x][2] if x in hierarchy_dict else None)\n",
    "train_df[\"class\"] = train_df[\"id\"].map(lambda x: hierarchy_dict[x][3] if x in hierarchy_dict else None)\n",
    "train_df[\"order\"] = train_df[\"id\"].map(lambda x: hierarchy_dict[x][4] if x in hierarchy_dict else None)\n",
    "train_df[\"family\"] = train_df[\"id\"].map(lambda x: hierarchy_dict[x][5] if x in hierarchy_dict else None)\n",
    "train_df[\"genus\"] = train_df[\"id\"].map(lambda x: hierarchy_dict[x][6] if x in hierarchy_dict else None)\n",
    "train_df[\"species\"] = train_df[\"id\"].map(lambda x: hierarchy_dict[x][7] if x in hierarchy_dict else None)\n",
    "\n",
    "# Drop id column from train_df\n",
    "train_df = train_df.drop(columns=[\"id\"])\n",
    "\n",
    "# Turn hierarchy annotations in train_df from floats to ints and then to strings if they are not null\n",
    "\n",
    "train_df[\"domain\"] = train_df[\"domain\"].apply(lambda x: str(int(x)) if pd.notnull(x) else x)\n",
    "train_df[\"kingdom\"] = train_df[\"kingdom\"].apply(lambda x: str(int(x)) if pd.notnull(x) else x)\n",
    "train_df[\"phylum\"] = train_df[\"phylum\"].apply(lambda x: str(int(x)) if pd.notnull(x) else x)\n",
    "train_df[\"class\"] = train_df[\"class\"].apply(lambda x: str(int(x)) if pd.notnull(x) else x)\n",
    "train_df[\"order\"] = train_df[\"order\"].apply(lambda x: str(int(x)) if pd.notnull(x) else x)\n",
    "train_df[\"family\"] = train_df[\"family\"].apply(lambda x: str(int(x)) if pd.notnull(x) else x)\n",
    "train_df[\"genus\"] = train_df[\"genus\"].apply(lambda x: str(int(x)) if pd.notnull(x) else x)\n",
    "train_df[\"species\"] = train_df[\"species\"].apply(lambda x: str(int(x)) if pd.notnull(x) else x)\n",
    "\n",
    "# Save train_df to csv\n",
    "train_df.to_csv(\"data/train/annotations.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get hierarchy and hierarchy dict without moving annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hierarchy dict:  {2: [2, 134, 7, 136, 23, 24, 25, 154, 155, 151, 37, 45, 46, 175, 173, 48, 187, 190, 81, 92, 96, 99], 23: [99, 37, 134, 136, 45, 46, 175, 173, 81, 23, 154, 155, 92, 190], 45: [99, 45, 154, 155, 190], 99: [154, 99, 155, 190], 155: [155], 4: [128, 4, 133, 8, 11, 140, 13, 142, 17, 146, 148, 21, 149, 152, 153, 28, 29, 157, 159, 160, 31, 34, 35, 36, 166, 42, 172, 177, 180, 53, 56, 185, 184, 188, 189, 62, 191, 64, 69, 70, 74, 78, 87, 94, 101, 102, 103, 108, 109, 113, 120, 122], 17: [140, 142, 17, 146, 149, 153, 159, 160, 34, 35, 177, 180, 53, 185, 189, 69, 70, 78, 94, 101, 103, 109, 113, 120], 53: [160, 101, 103, 140, 177, 113, 53], 101: [160, 113, 101], 113: [160, 113], 160: [160], 35: [35, 70, 78, 142, 146, 180, 120, 153, 189], 70: [70, 146, 120, 153, 189], 153: [153, 189], 3: [129, 130, 131, 3, 132, 135, 143, 15, 145, 18, 147, 20, 150, 26, 30, 158, 32, 162, 165, 167, 40, 169, 170, 171, 44, 174, 51, 52, 181, 55, 183, 58, 59, 60, 61, 186, 67, 68, 73, 75, 76, 77, 79, 82, 91, 93, 95, 97, 105, 107, 111, 112, 115, 118, 123, 124, 127], 20: [129, 131, 143, 145, 147, 20, 158, 167, 40, 169, 170, 44, 52, 181, 183, 61, 67, 73, 76, 77, 91, 93, 105, 107, 111, 123, 124, 127], 52: [129, 131, 143, 145, 147, 169, 170, 52, 181, 183, 67, 73, 77, 91, 93, 107, 111, 123, 127], 77: [129, 170, 131, 77], 131: [131], 1: [1, 137, 141, 144, 19, 27, 33, 163, 164, 38, 178, 179, 182, 65, 71, 80, 83, 84, 88, 89, 116, 117, 125], 19: [137, 141, 144, 19, 27, 33, 163, 164, 38, 178, 179, 182, 65, 71, 80, 83, 84, 88, 89, 116, 117, 125], 38: [84, 38], 84: [84], 189: [189], 33: [33, 65, 163, 164, 71, 137, 141, 80, 144, 178, 83, 116, 117, 182, 179, 88, 89, 125], 88: [88, 163, 116], 116: [163, 116], 163: [163], 8: [64, 128, 36, 133, 8, 74, 172, 28, 152, 56, 188], 56: [128, 133, 74, 172, 56], 74: [128, 74, 172, 133], 128: [128], 83: [137, 83], 137: [137], 0: [0, 100, 104, 49, 54, 22], 22: [100, 104, 49, 54, 22], 49: [49, 100], 100: [100], 5: [5, 41, 10, 139, 9, 43, 14, 106, 176, 86, 119, 57, 90], 9: [9, 106, 43, 119, 57, 90], 43: [90, 43, 119], 90: [90, 119], 119: [119], 11: [166, 11, 108, 148, 184, 122, 62, 31], 25: [25], 89: [141, 178, 179, 89, 125], 141: [178, 179, 141], 178: [178], 129: [129, 170], 170: [170], 67: [67, 169, 143, 181, 127], 143: [181, 143], 181: [181], 6: [6, 138, 12, 16, 156, 161, 39, 168, 47, 50, 63, 66, 72, 85, 98, 110, 114, 121, 126], 16: [98, 39, 168, 72, 110, 16, 50, 121, 156, 126, 63], 50: [168, 72, 50, 121, 126, 63], 63: [168, 126, 63], 126: [168, 126], 168: [168], 54: [104, 54], 104: [104], 21: [42, 21, 87], 146: [146], 15: [130, 132, 135, 15, 26, 30, 32, 165, 171, 174, 51, 58, 59, 60, 68, 75, 79, 82, 112, 118], 26: [130, 132, 135, 171, 75, 174, 79, 112, 82, 26, 59, 60], 30: [30], 40: [167, 40, 76, 124, 61], 76: [76], 36: [64, 188, 36, 152], 64: [64, 188, 152], 152: [152, 188], 188: [188], 103: [177, 140, 103], 140: [177, 140], 177: [177], 34: [34, 69, 109, 149, 185, 94, 159], 69: [109, 69, 159], 109: [109, 159], 159: [159], 13: [102, 13, 157, 29, 191], 29: [191, 29, 102, 157], 102: [157, 102, 191], 157: [157, 191], 191: [191], 94: [185, 149, 94], 149: [185, 149], 185: [185], 79: [171, 132, 79], 132: [171, 132], 171: [171], 72: [72, 121], 121: [121], 65: [65], 59: [112, 59], 112: [112], 78: [142, 180, 78], 142: [180, 142], 180: [180], 14: [14], 18: [97, 162, 18, 115, 150, 55, 186, 95], 55: [97, 162, 115, 150, 55, 186, 95], 97: [97, 162, 115], 115: [162, 115], 162: [162], 10: [41, 10, 139, 176, 86], 41: [176, 41, 139, 86], 86: [176, 139, 86], 139: [176, 139], 176: [176], 46: [136, 92, 46, 175], 92: [136, 92, 175], 136: [136, 175], 175: [175], 127: [169, 127], 169: [169], 93: [145, 93], 145: [145], 39: [98, 156, 110, 39], 98: [98, 156, 110], 156: [156], 75: [75], 51: [51], 120: [120], 12: [161, 66, 138, 12, 47, 114, 85], 47: [161, 66, 138, 47, 114, 85], 66: [161, 66, 114], 114: [161, 114], 60: [130, 60], 130: [130], 44: [105, 44, 158], 105: [105, 158], 158: [158], 154: [154, 190], 82: [82, 174, 135], 135: [174, 135], 174: [174], 37: [81, 37, 134, 173], 81: [81, 173, 134], 134: [173, 134], 173: [173], 73: [73, 123], 123: [123], 28: [28], 24: [96, 48, 151, 24, 187], 48: [48, 187, 96, 151], 96: [96, 187, 151], 151: [187, 151], 187: [187], 107: [107, 111], 111: [111], 7: [7], 71: [164, 117, 71], 117: [164, 117], 164: [164], 80: [80, 144, 182], 144: [144, 182], 182: [182], 190: [190], 85: [138, 85], 138: [138], 133: [172, 133], 172: [172], 161: [161], 110: [110], 31: [166, 108, 148, 184, 122, 62, 31], 62: [122, 166, 62], 122: [122, 166], 166: [166], 108: [184, 148, 108], 148: [184, 148], 184: [184], 58: [58], 61: [124, 61, 167], 124: [124, 167], 167: [167], 179: [179], 42: [42, 87], 87: [87], 32: [32, 68, 165, 118], 68: [68, 165, 118], 118: [165, 118], 165: [165], 95: [186, 150, 95], 150: [186, 150], 186: [186], 27: [27], 125: [125], 91: [91, 147, 183], 147: [147, 183], 183: [183], 57: [57, 106], 106: [106]}\n",
      "Descendent matrix:  [[1 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 1 0]\n",
      " ...\n",
      " [0 0 0 ... 1 0 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "from utils.utils import get_hierarchy_from_df\n",
    "\n",
    "train_df = pd.read_csv(\"data/train/annotations.csv\")\n",
    "hierarchy_dict, descendent_matrix = get_hierarchy_from_df(train_df)\n",
    "\n",
    "print(\"Hierarchy dict: \", hierarchy_dict)\n",
    "print(\"Descendent matrix: \", descendent_matrix)\n",
    "\n",
    "# Save hierarchy dict to json files\n",
    "with open(\"cfg/hierarchy/hierarchy_dict.json\", \"w\") as f:\n",
    "    json.dump(hierarchy_dict, f)\n",
    "\n",
    "# Save descendent matrix as numpy array\n",
    "np.save(\"cfg/hierarchy/descendent_matrix.npy\", descendent_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for intra-taxon annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotations in original but not in converted:  set()\n",
      "Annotations in converted but not in original:  set()\n",
      "Number of rows where label check is False:  0\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "heirarchical_headers = [\"phylum\", \"class\", \"order\", \"family\", \"genus\", \"species\"]\n",
    "\n",
    "train_df = pd.read_csv(\"data/train/annotations.csv\")\n",
    "index_to_taxon_map = json.load(open(\"data/train/index_to_taxon.json\"))\n",
    "\n",
    "original_annotations_set = set(train_df[\"label\"].unique())\n",
    "assert len(original_annotations_set) == 79\n",
    "\n",
    "# For each row, collect the values of the heirarchical headers into a list if they are not null\n",
    "def collect_hierarchy(row):\n",
    "    return [row[header] for header in heirarchical_headers if pd.notnull(row[header])]\n",
    "\n",
    "# Create a new column \"hierarchy\" in train_df that contains the list of hierarchy values\n",
    "train_df[\"hierarchy\"] = train_df.apply(collect_hierarchy, axis=1)\n",
    "\n",
    "train_df[\"last_nodes\"] = train_df[\"hierarchy\"].apply(lambda x: x[-1] if len(x) > 0 else None)\n",
    "\n",
    "train_df[\"converted_last_nodes\"] = train_df[\"last_nodes\"].apply(\n",
    "    lambda x: index_to_taxon_map[str(int(x))]\n",
    "    )\n",
    "\n",
    "converted_annotations_set = set(train_df[\"converted_last_nodes\"].unique())\n",
    "\n",
    "print(\"Annotations in original but not in converted: \", original_annotations_set - converted_annotations_set)\n",
    "print(\"Annotations in converted but not in original: \", converted_annotations_set - original_annotations_set)\n",
    "\n",
    "\n",
    "# For each id in train_df, check if the converted last node matches the label exactly\n",
    "def check_label(row):\n",
    "    return row[\"converted_last_nodes\"] == row[\"label\"]\n",
    "\n",
    "train_df[\"label_check\"] = train_df.apply(check_label, axis=1)\n",
    "# Check if there are any rows where the label check is False\n",
    "label_check_false = train_df[train_df[\"label_check\"] == False]\n",
    "print(\"Number of rows where label check is False: \", len(label_check_false))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop Domain and Kingdom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df after dropping domain and kingdom: \n",
      "                        path                    label phylum class order  \\\n",
      "0  ./data/train/rois/1_1.png             Sebastolobus      2    23    45   \n",
      "1  ./data/train/rois/2_2.png  Apostichopus leukothele      4    17    53   \n",
      "2  ./data/train/rois/3_3.png              Scotoplanes      4    17    35   \n",
      "3  ./data/train/rois/4_4.png               Keratoisis      3    20    52   \n",
      "4  ./data/train/rois/4_5.png               Keratoisis      3    20    52   \n",
      "\n",
      "  family genus species  \n",
      "0     99   155     NaN  \n",
      "1    101   113     160  \n",
      "2     70   153     NaN  \n",
      "3     77   131     NaN  \n",
      "4     77   131     NaN  \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(\"data/train/annotations.csv\")\n",
    "index_to_taxon_map = json.load(open(\"data/train/index_to_taxon.json\"))\n",
    "taxon_to_index_map = json.load(open(\"data/train/taxon_to_index.json\"))\n",
    "\n",
    "heirarchical_headers = [\"domain\", \"kingdom\", \"phylum\", \"class\", \"order\", \"family\", \"genus\", \"species\"]\n",
    "\n",
    "# Drop Domain and Kingdom, subtract 1 from all other indices\n",
    "# First deal with train_df\n",
    "\n",
    "train_df.drop(columns=[\"domain\", \"kingdom\"], inplace=True)\n",
    "\n",
    "for header in heirarchical_headers[2:]:\n",
    "    train_df[header] = train_df[header].apply(lambda x: str(int(x) - 2) if pd.notnull(x) else x)\n",
    "\n",
    "print(\"train_df after dropping domain and kingdom: \")\n",
    "# print first 5 rows of train_df\n",
    "print(train_df.head())\n",
    "\n",
    "# Now deal with index_to_taxon_map\n",
    "new_index_to_taxon_map = {}\n",
    "for key, value in index_to_taxon_map.items():\n",
    "    if key == \"0\" or key == \"1\":\n",
    "        continue\n",
    "    else:\n",
    "        new_index_to_taxon_map[str(int(key) - 2)] = value\n",
    "\n",
    "# Now deal with taxon_to_index_map\n",
    "new_taxon_to_index_map = {}\n",
    "for key, value in taxon_to_index_map.items():\n",
    "    if value == \"Eukaryote\" or value == \"Anamalia\":\n",
    "        continue\n",
    "    else:\n",
    "        new_taxon_to_index_map[key] = str(int(value) - 2)\n",
    "\n",
    "\n",
    "# Save new index_to_taxon_map and taxon_to_index_map to json\n",
    "with open(\"data/train/index_to_taxon.json\", \"w\") as f:\n",
    "    json.dump(new_index_to_taxon_map, f)\n",
    "with open(\"data/train/taxon_to_index.json\", \"w\") as f:\n",
    "    json.dump(new_taxon_to_index_map, f)\n",
    "\n",
    "# Save train_df to csv\n",
    "train_df.to_csv(\"data/train/annotations.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make similar adjustments to descendent matrix and hierarchy dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "descendent_matrix shape:  (194, 194)\n",
      "descendent_matrix:  [[1 1 1 ... 1 1 1]\n",
      " [0 1 1 ... 1 1 1]\n",
      " [0 0 1 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 1 0 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "\n",
    "descendent_matrix = np.load(\"cfg/hierarchy/descendent_matrix.npy\")\n",
    "hierarchy_dict = json.load(open(\"cfg/hierarchy/hierarchy_dict.json\"))\n",
    "\n",
    "print(\"descendent_matrix shape: \", descendent_matrix.shape)\n",
    "print(\"descendent_matrix: \", descendent_matrix)\n",
    "\n",
    "# Drop first two rows and columns\n",
    "new_descendent_matrix = descendent_matrix[2:, 2:]\n",
    "\n",
    "# Assert that the new descendent matrix rows and columns are the same as the original descendent matrix for the new ranges\n",
    "for row in range(new_descendent_matrix.shape[0]):\n",
    "    for col in range(new_descendent_matrix.shape[1]):\n",
    "        assert new_descendent_matrix[row, col] == descendent_matrix[row + 2, col + 2]\n",
    "\n",
    "# Save new hierarchy_dict to file\n",
    "# Drop 0 and 1 keys from hierarchy_dict along with their values\n",
    "# Subtract 2 from all other keys and values\n",
    "# Order the keys and values in new_hierarchy_dict\n",
    "new_hierarchy_dict = {}\n",
    "for key, value in hierarchy_dict.items():\n",
    "    if key == \"0\" or key == \"1\":\n",
    "        continue\n",
    "    else:\n",
    "        new_hierarchy_dict[str(int(key) - 2)] = [str(int(x) - 2) for x in value]\n",
    "\n",
    "# Save new descendent matrix to file\n",
    "np.save(\"cfg/hierarchy/descendent_matrix.npy\", new_descendent_matrix)\n",
    "\n",
    "# Save new hierarchy_dict to json\n",
    "with open(\"cfg/hierarchy/hierarchy_dict.json\", \"w\") as f:\n",
    "    json.dump(new_hierarchy_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing for cost_weighted_ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 4\n",
      "Cost matrix shape: torch.Size([3, 3])\n",
      "Expanded cost matrix shape: torch.Size([4, 3, 3])\n",
      "Ex cost mat tensor([[[0, 1, 5],\n",
      "         [1, 0, 3],\n",
      "         [5, 3, 0]],\n",
      "\n",
      "        [[0, 1, 5],\n",
      "         [1, 0, 3],\n",
      "         [5, 3, 0]],\n",
      "\n",
      "        [[0, 1, 5],\n",
      "         [1, 0, 3],\n",
      "         [5, 3, 0]],\n",
      "\n",
      "        [[0, 1, 5],\n",
      "         [1, 0, 3],\n",
      "         [5, 3, 0]]])\n",
      "Targets tensor([0, 0, 2, 2])\n",
      "Applied weights shape: torch.Size([4, 3])\n",
      "Applied weights: tensor([[0, 1, 5],\n",
      "        [0, 1, 5],\n",
      "        [5, 3, 0],\n",
      "        [5, 3, 0]])\n",
      "Inputs probabilities shape: torch.Size([4, 3])\n",
      "Inverse probabilities shape: torch.Size([4, 3])\n",
      "Log probabilities shape: torch.Size([4, 3])\n",
      "Log probabilities: tensor([[-0.4102, -1.4318, -2.3269],\n",
      "        [-2.0196, -0.5849, -1.1708],\n",
      "        [-0.3712, -1.9036, -1.8259],\n",
      "        [-1.6225, -0.5598, -1.4642]])\n",
      "Log inverse probabilities shape: torch.Size([4, 3])\n",
      "Log inverse probabilities: tensor([[-1.0892, -0.2730, -0.1027],\n",
      "        [-0.1424, -0.8146, -0.3712],\n",
      "        [-1.1708, -0.1614, -0.1756],\n",
      "        [-0.2199, -0.8471, -0.2630]])\n",
      "Selected log probabilities shape: torch.Size([4])\n",
      "Selected log probabilities: tensor([-0.4102, -2.0196, -1.8259, -1.4642])\n",
      "Selected log inverse probabilities shape: torch.Size([8])\n",
      "Selected log inverse probabilities: tensor([-0.2730, -0.1027, -0.8146, -0.3712, -1.1708, -0.1614, -0.2199, -0.8471])\n",
      "Log args shape: torch.Size([4, 3])\n",
      "Log args: tensor([[-0.4102, -0.2730, -0.1027],\n",
      "        [-2.0196, -0.8146, -0.3712],\n",
      "        [-1.1708, -0.1614, -1.8259],\n",
      "        [-0.2199, -0.8471, -1.4642]])\n",
      "tensor([[-0.0000, -0.2730, -0.5135],\n",
      "        [-0.0000, -0.8146, -1.8562],\n",
      "        [-5.8542, -0.4842, -0.0000],\n",
      "        [-1.0995, -2.5413, -0.0000]])\n",
      "tensor([0.7864, 2.6708, 6.3384, 3.6408])\n",
      "Loss shape: torch.Size([4])\n",
      "Loss:  3.359088897705078\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from utils.cost_weighted_ce import CostWeightedCELossWithLogits\n",
    "\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "cost_matrix = torch.tensor(\n",
    "    [\n",
    "        [0,1,5],\n",
    "        [1,0,3],\n",
    "        [5,3,0],\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_outs = torch.randn(batch_size, 3)\n",
    "test_targets = torch.randint(0, 3, (batch_size,))\n",
    "softmax = torch.nn.Softmax(dim=1)\n",
    "softmax_outs = softmax(test_outs)\n",
    "\n",
    "criterion = CostWeightedCELossWithLogits(cost_matrix)\n",
    "\n",
    "loss = criterion(test_outs, test_targets)\n",
    "print(\"Loss: \", loss.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Distance Calcuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds:  tensor([0, 0, 1, 1])\n",
      "Targets:  tensor([2, 2, 2, 2])\n",
      "Distance:  4.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from utils.cost_weighted_ce import CalcDistance\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "cost_matrix = torch.tensor(\n",
    "    [\n",
    "        [0,1,5],\n",
    "        [1,0,3],\n",
    "        [5,3,0],\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_outs = torch.randn(batch_size, 3)\n",
    "test_targets = torch.randint(0, 3, (batch_size,))\n",
    "softmax = torch.nn.Softmax(dim=1)\n",
    "softmax_outs = softmax(test_outs)\n",
    "\n",
    "_, preds = torch.max(softmax_outs, 1)\n",
    "print(\"Preds: \", preds)\n",
    "print(\"Targets: \", test_targets)\n",
    "\n",
    "calc_distance = CalcDistance(cost_matrix)\n",
    "\n",
    "distance = calc_distance(preds, test_targets)\n",
    "print(\"Distance: \", distance.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
