{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move taxon annotations over to main file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(\"data/train/annotations.csv\")\n",
    "hierarchy_annotations = pd.read_csv(\"data/train/hierarchy_labels_train.csv\")\n",
    "\n",
    "train_df[\"id\"] = train_df[\"path\"].apply(lambda x: x.split(\"/\")[-1].split(\".\")[0])\n",
    "hierarchy_annotations[\"id\"] = hierarchy_annotations[\"annotation_id\"].apply(lambda x: x.split(\".\")[0])\n",
    "\n",
    "# Enable this line if hierarchical ids are in the format \"roi_image\"\n",
    "# hierarchy_annotations[\"id\"] = hierarchy_annotations[\"id\"].apply(lambda x: x.split(\"_\")[-1] + \"_\" + x.split(\"_\")[0])\n",
    "\n",
    "# Make hierarchy_annotations headers lowercase\n",
    "hierarchy_annotations.columns = hierarchy_annotations.columns.str.lower()\n",
    "# Move domain,kingdom,phylum,class,order,family,genus,species from hierarchy_annotations to train_df based on id\n",
    "# Create dictionary to map id to hierarchy annotations\n",
    "hierarchy_annotations = hierarchy_annotations[[\"id\", \"domain\", \"kingdom\", \"phylum\", \"class\", \"order\", \"family\", \"genus\", \"species\"]]\n",
    "hierarchy_dict = hierarchy_annotations.set_index(\"id\").T.to_dict(\"list\")\n",
    "\n",
    "train_df[\"domain\"] = train_df[\"id\"].map(lambda x: hierarchy_dict[x][0] if x in hierarchy_dict else None)\n",
    "train_df[\"kingdom\"] = train_df[\"id\"].map(lambda x: hierarchy_dict[x][1] if x in hierarchy_dict else None)   \n",
    "train_df[\"phylum\"] = train_df[\"id\"].map(lambda x: hierarchy_dict[x][2] if x in hierarchy_dict else None)\n",
    "train_df[\"class\"] = train_df[\"id\"].map(lambda x: hierarchy_dict[x][3] if x in hierarchy_dict else None)\n",
    "train_df[\"order\"] = train_df[\"id\"].map(lambda x: hierarchy_dict[x][4] if x in hierarchy_dict else None)\n",
    "train_df[\"family\"] = train_df[\"id\"].map(lambda x: hierarchy_dict[x][5] if x in hierarchy_dict else None)\n",
    "train_df[\"genus\"] = train_df[\"id\"].map(lambda x: hierarchy_dict[x][6] if x in hierarchy_dict else None)\n",
    "train_df[\"species\"] = train_df[\"id\"].map(lambda x: hierarchy_dict[x][7] if x in hierarchy_dict else None)\n",
    "\n",
    "# Drop id column from train_df\n",
    "train_df = train_df.drop(columns=[\"id\"])\n",
    "\n",
    "# Turn hierarchy annotations in train_df from floats to ints and then to strings if they are not null\n",
    "\n",
    "train_df[\"domain\"] = train_df[\"domain\"].apply(lambda x: str(int(x)) if pd.notnull(x) else x)\n",
    "train_df[\"kingdom\"] = train_df[\"kingdom\"].apply(lambda x: str(int(x)) if pd.notnull(x) else x)\n",
    "train_df[\"phylum\"] = train_df[\"phylum\"].apply(lambda x: str(int(x)) if pd.notnull(x) else x)\n",
    "train_df[\"class\"] = train_df[\"class\"].apply(lambda x: str(int(x)) if pd.notnull(x) else x)\n",
    "train_df[\"order\"] = train_df[\"order\"].apply(lambda x: str(int(x)) if pd.notnull(x) else x)\n",
    "train_df[\"family\"] = train_df[\"family\"].apply(lambda x: str(int(x)) if pd.notnull(x) else x)\n",
    "train_df[\"genus\"] = train_df[\"genus\"].apply(lambda x: str(int(x)) if pd.notnull(x) else x)\n",
    "train_df[\"species\"] = train_df[\"species\"].apply(lambda x: str(int(x)) if pd.notnull(x) else x)\n",
    "\n",
    "# Save train_df to csv\n",
    "train_df.to_csv(\"data/train/annotations.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get hierarchy and hierarchy dict without moving annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "from utils.utils import get_hierarchy_from_df\n",
    "\n",
    "train_df = pd.read_csv(\"data/train/annotations.csv\")\n",
    "hierarchy_dict, descendent_matrix = get_hierarchy_from_df(train_df)\n",
    "\n",
    "print(\"Hierarchy dict: \", hierarchy_dict)\n",
    "print(\"Descendent matrix: \", descendent_matrix)\n",
    "\n",
    "# Save hierarchy dict to json files\n",
    "with open(\"cfg/hierarchy/hierarchy_dict.json\", \"w\") as f:\n",
    "    json.dump(hierarchy_dict, f)\n",
    "\n",
    "# Save descendent matrix as numpy array\n",
    "np.save(\"cfg/hierarchy/descendent_matrix.npy\", descendent_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for intra-taxon annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotations in original but not in converted:  set()\n",
      "Annotations in converted but not in original:  set()\n",
      "Number of rows where label check is False:  0\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "heirarchical_headers = [\"phylum\", \"class\", \"order\", \"family\", \"genus\", \"species\"]\n",
    "\n",
    "train_df = pd.read_csv(\"data/train/annotations.csv\")\n",
    "index_to_taxon_map = json.load(open(\"data/train/index_to_taxon.json\"))\n",
    "\n",
    "original_annotations_set = set(train_df[\"label\"].unique())\n",
    "assert len(original_annotations_set) == 79\n",
    "\n",
    "# For each row, collect the values of the heirarchical headers into a list if they are not null\n",
    "def collect_hierarchy(row):\n",
    "    return [row[header] for header in heirarchical_headers if pd.notnull(row[header])]\n",
    "\n",
    "# Create a new column \"hierarchy\" in train_df that contains the list of hierarchy values\n",
    "train_df[\"hierarchy\"] = train_df.apply(collect_hierarchy, axis=1)\n",
    "\n",
    "train_df[\"last_nodes\"] = train_df[\"hierarchy\"].apply(lambda x: x[-1] if len(x) > 0 else None)\n",
    "\n",
    "train_df[\"converted_last_nodes\"] = train_df[\"last_nodes\"].apply(\n",
    "    lambda x: index_to_taxon_map[str(int(x))]\n",
    "    )\n",
    "\n",
    "converted_annotations_set = set(train_df[\"converted_last_nodes\"].unique())\n",
    "\n",
    "print(\"Annotations in original but not in converted: \", original_annotations_set - converted_annotations_set)\n",
    "print(\"Annotations in converted but not in original: \", converted_annotations_set - original_annotations_set)\n",
    "\n",
    "\n",
    "# For each id in train_df, check if the converted last node matches the label exactly\n",
    "def check_label(row):\n",
    "    return row[\"converted_last_nodes\"] == row[\"label\"]\n",
    "\n",
    "train_df[\"label_check\"] = train_df.apply(check_label, axis=1)\n",
    "# Check if there are any rows where the label check is False\n",
    "label_check_false = train_df[train_df[\"label_check\"] == False]\n",
    "print(\"Number of rows where label check is False: \", len(label_check_false))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop Domain and Kingdom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df after dropping domain and kingdom: \n",
      "                        path                    label phylum class order  \\\n",
      "0  ./data/train/rois/1_1.png             Sebastolobus      2    23    45   \n",
      "1  ./data/train/rois/2_2.png  Apostichopus leukothele      4    17    53   \n",
      "2  ./data/train/rois/3_3.png              Scotoplanes      4    17    35   \n",
      "3  ./data/train/rois/4_4.png               Keratoisis      3    20    52   \n",
      "4  ./data/train/rois/4_5.png               Keratoisis      3    20    52   \n",
      "\n",
      "  family genus species  \n",
      "0     99   155     NaN  \n",
      "1    101   113     160  \n",
      "2     70   153     NaN  \n",
      "3     77   131     NaN  \n",
      "4     77   131     NaN  \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(\"data/train/annotations.csv\")\n",
    "index_to_taxon_map = json.load(open(\"data/train/index_to_taxon.json\"))\n",
    "taxon_to_index_map = json.load(open(\"data/train/taxon_to_index.json\"))\n",
    "\n",
    "heirarchical_headers = [\"domain\", \"kingdom\", \"phylum\", \"class\", \"order\", \"family\", \"genus\", \"species\"]\n",
    "\n",
    "# Drop Domain and Kingdom, subtract 1 from all other indices\n",
    "# First deal with train_df\n",
    "\n",
    "train_df.drop(columns=[\"domain\", \"kingdom\"], inplace=True)\n",
    "\n",
    "for header in heirarchical_headers[2:]:\n",
    "    train_df[header] = train_df[header].apply(lambda x: str(int(x) - 2) if pd.notnull(x) else x)\n",
    "\n",
    "print(\"train_df after dropping domain and kingdom: \")\n",
    "# print first 5 rows of train_df\n",
    "print(train_df.head())\n",
    "\n",
    "# Now deal with index_to_taxon_map\n",
    "new_index_to_taxon_map = {}\n",
    "for key, value in index_to_taxon_map.items():\n",
    "    if key == \"0\" or key == \"1\":\n",
    "        continue\n",
    "    else:\n",
    "        new_index_to_taxon_map[str(int(key) - 2)] = value\n",
    "\n",
    "# Now deal with taxon_to_index_map\n",
    "new_taxon_to_index_map = {}\n",
    "for key, value in taxon_to_index_map.items():\n",
    "    if value == \"Eukaryote\" or value == \"Anamalia\":\n",
    "        continue\n",
    "    else:\n",
    "        new_taxon_to_index_map[key] = str(int(value) - 2)\n",
    "\n",
    "\n",
    "# Save new index_to_taxon_map and taxon_to_index_map to json\n",
    "with open(\"data/train/index_to_taxon.json\", \"w\") as f:\n",
    "    json.dump(new_index_to_taxon_map, f)\n",
    "with open(\"data/train/taxon_to_index.json\", \"w\") as f:\n",
    "    json.dump(new_taxon_to_index_map, f)\n",
    "\n",
    "# Save train_df to csv\n",
    "train_df.to_csv(\"data/train/annotations.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make similar adjustments to descendent matrix and hierarchy dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "descendent_matrix shape:  (194, 194)\n",
      "descendent_matrix:  [[1 1 1 ... 1 1 1]\n",
      " [0 1 1 ... 1 1 1]\n",
      " [0 0 1 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 1 0 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "\n",
    "descendent_matrix = np.load(\"cfg/hierarchy/descendent_matrix.npy\")\n",
    "hierarchy_dict = json.load(open(\"cfg/hierarchy/hierarchy_dict.json\"))\n",
    "\n",
    "print(\"descendent_matrix shape: \", descendent_matrix.shape)\n",
    "print(\"descendent_matrix: \", descendent_matrix)\n",
    "\n",
    "# Drop first two rows and columns\n",
    "new_descendent_matrix = descendent_matrix[2:, 2:]\n",
    "\n",
    "# Assert that the new descendent matrix rows and columns are the same as the original descendent matrix for the new ranges\n",
    "for row in range(new_descendent_matrix.shape[0]):\n",
    "    for col in range(new_descendent_matrix.shape[1]):\n",
    "        assert new_descendent_matrix[row, col] == descendent_matrix[row + 2, col + 2]\n",
    "\n",
    "# Save new hierarchy_dict to file\n",
    "# Drop 0 and 1 keys from hierarchy_dict along with their values\n",
    "# Subtract 2 from all other keys and values\n",
    "# Order the keys and values in new_hierarchy_dict\n",
    "new_hierarchy_dict = {}\n",
    "for key, value in hierarchy_dict.items():\n",
    "    if key == \"0\" or key == \"1\":\n",
    "        continue\n",
    "    else:\n",
    "        new_hierarchy_dict[str(int(key) - 2)] = [str(int(x) - 2) for x in value]\n",
    "\n",
    "# Save new descendent matrix to file\n",
    "np.save(\"cfg/hierarchy/descendent_matrix.npy\", new_descendent_matrix)\n",
    "\n",
    "# Save new hierarchy_dict to json\n",
    "with open(\"cfg/hierarchy/hierarchy_dict.json\", \"w\") as f:\n",
    "    json.dump(new_hierarchy_dict, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
